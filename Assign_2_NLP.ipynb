{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmcxP+POKNo/kKh+Pxxk0/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MOHAMMEDASHRAF310/Courser-Test/blob/main/Assign_2_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBZZCxkPrhQW"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "# Sample documents\n",
        "documents = [\n",
        "    \"Machine learning is a subset of artificial intelligence.\",\n",
        "    \"Data science involves analyzing data to extract insights.\",\n",
        "    \"Blockchain technology is revolutionizing finance and beyond.\"\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBZwJbWOrps1",
        "outputId": "93114d78-e4b0-4168-b074-23236647d14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "    # Convert to lowercase\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "nu2w5BW7rrpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert documents to TF-IDF vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(tokenizer=preprocess_text)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)"
      ],
      "metadata": {
        "id": "WUn_AJiPruDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Compute L2 normalization\n",
        "tfidf_matrix_normalized = normalize(tfidf_matrix, norm='l2')\n"
      ],
      "metadata": {
        "id": "DwvIkArerwyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display unique words\n",
        "unique_words = tfidf_vectorizer.get_feature_names_out()\n",
        "print(\"Unique words:\", unique_words)\n",
        "\n",
        "# Display TF-IDF scores\n",
        "print(\"TF-IDF scores:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tr2K96ErzF1",
        "outputId": "e50cf8f4-2332-4107-d464-5b890a0c4ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words: ['.' 'analyzing' 'artificial' 'beyond' 'blockchain' 'data' 'extract'\n",
            " 'finance' 'insight' 'intelligence' 'involves' 'learning' 'machine'\n",
            " 'revolutionizing' 'science' 'subset' 'technology']\n",
            "TF-IDF scores:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, doc in enumerate(documents):\n",
        "    print(\"Document\", i+1, \":\")\n",
        "    feature_index = tfidf_matrix[i,:].nonzero()[1]\n",
        "    tfidf_scores = zip(feature_index, [tfidf_matrix[i, x] for x in feature_index])\n",
        "    for w, s in [(unique_words[i], s) for (i, s) in tfidf_scores]:\n",
        "        print(w, \":\", s)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BQ2ImvTr261",
        "outputId": "11f6c4d0-f418-499a-cea8-e2b9d8c33e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1 :\n",
            ". : 0.25537359879528915\n",
            "intelligence : 0.4323850887896905\n",
            "artificial : 0.4323850887896905\n",
            "subset : 0.4323850887896905\n",
            "learning : 0.4323850887896905\n",
            "machine : 0.4323850887896905\n",
            "\n",
            "Document 2 :\n",
            "insight : 0.32705547923242223\n",
            "extract : 0.32705547923242223\n",
            "analyzing : 0.32705547923242223\n",
            "involves : 0.32705547923242223\n",
            "science : 0.32705547923242223\n",
            "data : 0.6541109584648445\n",
            ". : 0.19316423462032448\n",
            "\n",
            "Document 3 :\n",
            "beyond : 0.4323850887896905\n",
            "finance : 0.4323850887896905\n",
            "revolutionizing : 0.4323850887896905\n",
            "technology : 0.4323850887896905\n",
            "blockchain : 0.4323850887896905\n",
            ". : 0.25537359879528915\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display normalized TF-IDF scores\n",
        "print(\"Normalized TF-IDF scores:\")\n",
        "for i, doc in enumerate(documents):\n",
        "    print(\"Document\", i+1, \":\")\n",
        "    feature_index = tfidf_matrix_normalized[i,:].nonzero()[1]\n",
        "    tfidf_scores = zip(feature_index, [tfidf_matrix_normalized[i, x] for x in feature_index])\n",
        "    for w, s in [(unique_words[i], s) for (i, s) in tfidf_scores]:\n",
        "        print(w, \":\", s)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDqiQyiUr4y1",
        "outputId": "ed7ab54a-a007-4513-8975-762548e37f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized TF-IDF scores:\n",
            "Document 1 :\n",
            ". : 0.2553735987952892\n",
            "intelligence : 0.43238508878969056\n",
            "artificial : 0.43238508878969056\n",
            "subset : 0.43238508878969056\n",
            "learning : 0.43238508878969056\n",
            "machine : 0.43238508878969056\n",
            "\n",
            "Document 2 :\n",
            "insight : 0.32705547923242223\n",
            "extract : 0.32705547923242223\n",
            "analyzing : 0.32705547923242223\n",
            "involves : 0.32705547923242223\n",
            "science : 0.32705547923242223\n",
            "data : 0.6541109584648445\n",
            ". : 0.19316423462032448\n",
            "\n",
            "Document 3 :\n",
            "beyond : 0.4323850887896905\n",
            "finance : 0.4323850887896905\n",
            "revolutionizing : 0.4323850887896905\n",
            "technology : 0.4323850887896905\n",
            "blockchain : 0.4323850887896905\n",
            ". : 0.25537359879528915\n",
            "\n"
          ]
        }
      ]
    }
  ]
}